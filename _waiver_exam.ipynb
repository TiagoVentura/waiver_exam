{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f49d5ba",
   "metadata": {},
   "source": [
    "<h1><center> PPOL 5203 Data Science I: Foundations <br><br> \n",
    "<font color='grey'>Waiver Exame<br><br>\n",
    "Tiago Ventura</center></center> <h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843f951",
   "metadata": {},
   "source": [
    "## Question 1: Version Control (20pts)\n",
    "\n",
    "Your first question will test your skills on git. You need to solve the challenges of this Git Scavenger task  \n",
    "\n",
    "Here is the link of the task:\n",
    "\n",
    "https://github.com/PPOL-5203-2023/git-scavenger-hunt-20203\n",
    "\n",
    "Provide your answers below in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add your response here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b61154",
   "metadata": {},
   "source": [
    "## Question 2: Python Fundamentals - Functions & List Comprehension (20pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10311398",
   "metadata": {},
   "source": [
    "Using the following data, write a function called  mutate() that takes the nested list data and a new list as input and returns a new nested list combining the input list to the nested list. Notice, your single function must support concatenating the nested list with the input list by row or by column.  \n",
    "\n",
    "Important points:\n",
    "\n",
    "- You should use an argument called axis to indicate the row-wise or column-wise option.\n",
    "\n",
    "- Make sure the function can only deal with inputs of the same size for the column-wise operation \n",
    "\n",
    "- Make sure you include a docstring with your function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5a7bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data\n",
    "data = [\n",
    "  [\"Var1\",\"Var2\",\"Var3\"],\n",
    "  [1,\"Apples\",True],\n",
    "  [4,\"Horses\",None],\n",
    "  [-1,\"Small Birds\",False],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226ba672",
   "metadata": {},
   "source": [
    "### Question 2.1 Practice with iteration/list comprehension (10pts)\n",
    "\n",
    "Here, we provide you with a list containing the course codes for different McCourt/Georgetown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9fbc97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## course code list \n",
    "course_codes = [\"PPOL 506\", \"PPOL 560\", \"PPOL 564\", \"SOCI 393\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cd1366",
   "metadata": {},
   "source": [
    "### 2.2 Using list comprehension to keep all elements / transform them \n",
    "\n",
    "- A. Create a new list---course_codes_ns-- that removes the spaces in each course code--- eg PPOL 506 should become PPOL506\n",
    "- B. Print `course_codes_ns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a45bd6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a75ce",
   "metadata": {},
   "source": [
    "## 3.2 Using list comprehension to subset a list\n",
    "\n",
    "- A. using course_codes_ns, create a new list just with courses with ppol in the name; store it as `course_codes_ppol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e1585ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e35af8",
   "metadata": {},
   "source": [
    "## 3.3 Dictionary Comprehension \n",
    "\n",
    "- A. Create a second list with the grades you which to have in each of these courses\n",
    "- B. Use a dictionary Comprehension to create a dictionary with keys for the course number, and values for your grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d57b8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2878ca7",
   "metadata": {},
   "source": [
    "## Question 3: Data Wrangling in Pandas (20pts)\n",
    "\n",
    "This problem set will focus on data exploration and data wrangling using Pandas. \n",
    "\n",
    "## Dataset\n",
    "\n",
    "For this problem set, we will with a mix of electoral and survey data.  Primarely, you will work with data from the 2020 Cooperative Election Study (CCES).  \n",
    "\n",
    "## CCES\n",
    "\n",
    "The Cooperative Election Study, or CCES, seeks to study how Americans view and hold their representatives accountable during elections, how they voted and their electoral experiences, and how their behavior and experiences vary with political geography and social context. The CCES is a 50,000+ person national stratified sample survey administered by YouGov. \n",
    "\n",
    "The survey consists of two waves in election years. In the pre-election wave, respondents answer two-thirds of the questionnaire. This segment of the survey asks about general political attitudes, various demographic factors, assessment of roll call voting choices, political information, and vote intentions. The pre-election wave is in the field from xlate September to late October. In the post-election wave, respondents answer the other third of the questionnaire, mostly consisting of items related to the election that just occurred. The post-election wave is administered in November.\n",
    "\n",
    "## Data Documentation\n",
    "\n",
    "Information about the CCES project can be found in their website: https://cces.gov.harvard.edu/\n",
    "\n",
    "Documentation for the 2020 wave can be download in the following links: \n",
    "\n",
    "- Pre-Election Survey: https://dataverse.harvard.edu/file.xhtml?fileId=4462965&version=4.0\n",
    "\n",
    "- Post-Election Survey: https://dataverse.harvard.edu/file.xhtml?fileId=4462966&version=4.0\n",
    "\n",
    "- Full Guide: https://dataverse.harvard.edu/file.xhtml?fileId=5793681&version=4.0\n",
    "\n",
    "The full dataset and the three codebooks are available in the repository. This survey data is saved as `cces_2020.csv` inside of a compressed file. The documentation is inside of the documentation folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbc8ecb",
   "metadata": {},
   "source": [
    "## 0. Load packages and imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## basic functionality\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import plotnine\n",
    "\n",
    "\n",
    "# see all columns\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886f11de",
   "metadata": {},
   "source": [
    "## 1. Understand the Dataset (10pts)\n",
    "\n",
    "Our first step as data scientist is to understand the structure of the data. Do the following: \n",
    "\n",
    "\n",
    "- Open the `cces_2022.csv` as a pandas data frame. Open the dataset using only the set of columns saved in the `col_to_open`\n",
    "- What is the unit of analysis of this data frame?\n",
    "- Are these units unique? Or are these units duplicated over the rows?\n",
    "- How is the panel data (pre and post-election surveys) encoded in the data frame?\n",
    "- How many variables exist in the data frame?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "9fabac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_open = ['caseid', \n",
    "        \"gender\", \"gender_post\",\n",
    "        \"birthyr\", \"birthyr_post\",\n",
    "        'educ', \"race\", \"hispanic\",\n",
    "        \"pid3\",\n",
    "        \"votereg\", \"votereg_post\", \n",
    "        \"inputstate\", \"region\", \n",
    "        \"CC20_330a\", \"CC20_330b\", \"CC20_330c\",\n",
    "        \"CC20_331a\", \"CC20_331b\", \"CC20_331c\", \"CC20_331d\", \"CC20_331e\", \n",
    "         \"presvote16post\", \n",
    "         \"CC20_363\", \n",
    "         \"CC20_364b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eae60d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your responses. Split them across multiple cells!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a311be1f",
   "metadata": {},
   "source": [
    "## 2. Analyzing voter registration (10pts)\n",
    "\n",
    "In the survey, there are two self-reported measures for voter registration (`votereg` and `votereg_post`). If you want to understand better what voter registration means, read [here](https://electionlab.mit.edu/research/voter-registration)\n",
    "\n",
    "- Calculate the share of voters in the entire sample who were registered to vote in the first wave of the survey\n",
    "- Analyze the difference between voter registration across gender, race, and party identification. To do, you need to calculate the proportion of registered voters in each subgroup. \n",
    "- Create a new column indicating which voters reported having registered to vote only in the second wave of the survey. How many voters reported to have registered to vote only in the second wave?\n",
    "- Filter the dataset only with voters who report having registered to voter only in the second wave. Call this dataset `late_voters`. Look at the racial composition of late voters, and compare with the racial composition of the entire sample. What is the largest difference between the two groups?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491c79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your responses. Split them across multiple cells!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45adb630",
   "metadata": {},
   "source": [
    "## Question 4: Accessing the NYT API (20pts)\n",
    "\n",
    "For this exercise, we will work with the New York Times API. The idea here is for you to get practice interacting with an API. Your task is to build a simple wrapper for you to interact with the API, search for articles, and save your searches. \n",
    "\n",
    "Let's get started. Your tasks are: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d72a0",
   "metadata": {},
   "source": [
    "#### 3.1 - Get access to the New York York Times API\n",
    "\n",
    "- Follow the instructions here to get your credentials: https://developer.nytimes.com/get-started\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4820de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NYT API key from .env file\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "load_dotenv() \n",
    "nyt_key = \"x0EDyUVrnwG9ydemcYxdtqBr9joYcWps\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d70a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x0EDyUVrnwG9ydemcYxdtqBr9joYcWps'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53750e73",
   "metadata": {},
   "source": [
    "#### 3.2 Search API\n",
    "\n",
    "When you sign up for the account, you must register an application and choose which APIs you want to activate. Some options are Article Search API, Top Stories API, and Archive API but also include Movies Review or Book API. \n",
    "\n",
    "We will be working with the Search API. \n",
    "\n",
    "Read more about the search API here: https://developer.nytimes.com/docs/articlesearch-product/1/overview\n",
    "\n",
    "In your words, describe to me the main components of the search api. These are:\n",
    "\n",
    "- endpoint:\n",
    "\n",
    "- describe some of the main filters\n",
    "\n",
    "- Are there any required filters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3882d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8a41f9",
   "metadata": {},
   "source": [
    "#### 3.3 - Make your first API call\n",
    "\n",
    "Write code to make a simple API call. \n",
    "\n",
    "- Query the API to search for articles about Biden. \n",
    "\n",
    "- Make a get request\n",
    "\n",
    "- print only the status of the response\n",
    "\n",
    "**Tip**:\n",
    "\n",
    "- *the api key here is passed as a parameter, not as a http header*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "173b6d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a32f56",
   "metadata": {},
   "source": [
    "#### 3.4 - Add more elements to your query\n",
    "\n",
    "Now, add more parameters to your query. You can try the following parameters: \n",
    "    \n",
    "- begin_date\n",
    "\n",
    "- end_date\n",
    "\n",
    "- filters (only fq parameter)\n",
    "\n",
    "- pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4b2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81128249",
   "metadata": {},
   "source": [
    "#### 3.5 - Build a function for your wrapper\n",
    "\n",
    "Now, build a function to your wrapper. The inputs of the function should be all the parameters listed above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01674f74",
   "metadata": {},
   "source": [
    "## Question 5: Your first machine learning pipeline (20pts)\n",
    "\n",
    "Congrats! You were hired as a Data Scientist at the Integrity Institute. Your work will focus on creating models to measure the prevalence of misinformation on social media platforms. To do so, you will need to develop from scratch a machine learning pipeline to predict social media posts (tweets, facebook posts, posts on threads, anything textual) that contain misinformation. \n",
    "\n",
    "You boss just gave you your first batch of data. You need to describe to him all the steps you will take to build your machine learning pipeline. Describe: \n",
    "\n",
    "1) What is your outcome? Assuming the outcome is not defined (your data is not labelled), how will you suggest your colleagues to go about that? \n",
    "\n",
    "2) After you have your outcome, describe if this task is a predictive or inferential type of task. \n",
    "\n",
    "3) Then, explain how you would train your machine learning model. You description should mention the following concepts we saw in class: \n",
    "\n",
    "- Data Pre-Processing\n",
    "\n",
    "- Training vs testing\n",
    "\n",
    "- Model selection, hyper-parameter tunning and cross validation\n",
    "\n",
    "- Out-of-sample prediction and model accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144083b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
